​	K最近邻（k-Nearest Neighbor，kNN）分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路为：如果一个样本在特征空间中的k个最相似（即特征空间中最近邻）的样本中的大多数属于某一个类别，则该样本也属于这个类别。	

​	所谓k近邻，即是给定一个训练数据集，对新的输入实例，在训练数据集中找到与该实例最邻近的K个实例（也就是上面说的k个邻居），这k个实例的多数属于某个类，就把该输入实例分类到这个类中。 

​	算法描述：

​	·（1）计算测试数据与各个训练数据之间的距离

​	·（2）按照距离的递进关系进行排序

​	·（3）选取距离最小的K个点

​	·（4）确定前K个点所在类别的出现频率

​	·（5）返回前K个点中出现频率最高的类别作为测试数据的预测分类

tf.negative()：取相反数

tf.abs()         ：取绝对值

tf.argmin()   ：返回最小值的索引

目前正确率未达到100%，原因是k近邻的k取值不够合适，继续改进中。

步骤：

step1 计算距离 ： 求差----差值平方----平方后的差值累加-----求开方

step2 对距离进行排序，得到最小距离的索引

step 3: 选择k个最近邻

step 4: 计算k个最近邻中各类别出现的次数

step 5: 返回出现次数最多的类别标签